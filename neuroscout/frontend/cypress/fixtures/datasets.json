[{"active":true,"description":{"Acknowledgements":"We thank Terry Sacket and the rest of the DBIC (Dartmouth Brain Imaging Center) personnel for assistance in data collection, and Yaroslav Halchenko for preparing the BIDS dataset.","Authors":["Matteo Visconti di Oleggio Castello","Vassiki Chauhan","Guo Jiahui","M. Ida Gobbini"],"BIDSVersion":"1.3.0","DatasetDOI":"10.18112/openneuro.ds003017.v1.0.1","Funding":["NSF grant #1835200"],"HowToAcknowledge":"Please cite the corresponding paper Visconti di Oleggio Castello, M., Chauhan, V., Jiahui, G., & Gobbini, M. I. (2020). The Grand Budapest Hotel: an fMRI dataset in response to a socially-rich, naturalistic movie. In bioRxiv (p. 2020.07.14.203257).  https://doi.org/10.1101/2020.07.14.203257","License":"CC0","Name":"Budapest","ReferencesAndLinks":["https://github.com/mvdoc/budapest-fmri-data","https://doi.org/10.1101/2020.07.14.203257","https://openneuro.org/datasets/ds003017"]},"id":27,"long_description":"Twenty-five subjects watched the second half of the movie 'The Grand Budapest Hotel'.","mean_age":27.52,"mimetypes":["video/mp4","audio/x-wav","image/png","text/csv","text/plain"],"name":"Budapest","percent_female":0.52,"summary":"The Grand Budapest Hotel: an fMRI dataset in response to a socially-rich, naturalistic movie","tasks":[{"TR":1.0,"avg_run_duration":610,"id":48,"n_runs_subject":5,"n_subjects":25,"name":"movie","summary":"Movie watching"}],"url":"https://openneuro.org/datasets/ds0030175"},{"active":true,"description":{"Authors":["Lindsay M. Alexander","Jasmine Escalera","\u2026","Michael P. Milham"],"BIDSVersion":"1.0.2","Name":"Healthy_Brain_Network"},"id":8,"long_description":"The Healthy Brain Network is an initiative focused on creating a biobank comprised of data from 10,000 New York City area children and adolescents (ages 5-21), with a focused recruitment on children with one or more psychiatric symptoms.  Two short naturalistic clips (10-mins each) were watched during fMRI scanning as part of this broader protocol. Currently, data from a subset of participants is available for one task.","mean_age":null,"mimetypes":["video/x-matroska","image/png","text/plain","audio/x-wav","text/csv"],"name":"HealthyBrainNetwork","percent_female":null,"summary":"Movie clips from an adolescent development study","tasks":[{"TR":0.8,"avg_run_duration":597,"id":7,"n_runs_subject":1,"n_subjects":142,"name":"movieDM","summary":"AV Presentation: Despicable Me"}],"url":"http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/"},{"active":false,"description":{"Acknowledgements":"","Authors":["Tomoyasu Horikawa","Yukiyasu Kamitani"],"DatasetDOI":"","Funding":"","HowToAcknowledge":"","License":"","Name":"Generic Object Decoding (fMRI on ImageNet)","ReferencesAndLinks":["Horikawa & Kamitani (2017) Generic decoding of seen and imagined objects using hierarchical visual features. Nature Communications volume 8:15037. doi:10.1038/ncomms15037"]},"id":1,"long_description":null,"mean_age":null,"mimetypes":["image/jpeg"],"name":"generic_object_decoding","percent_female":null,"summary":"1,200 object images from various categories","tasks":[{"TR":3.0,"avg_run_duration":534,"id":1,"n_runs_subject":22,"n_subjects":5,"name":"perception","summary":"Visual Image perception"}],"url":"https://openneuro.org/datasets/ds001246/"},{"active":true,"description":{"Acknowledgements":"","Authors":["Baldassano, C.","Hasson, U.","Norman, K."],"BIDSVersion":"1.1.0","DatasetDOI":"10.18112/openneuro.ds001510.v1.0.3","Funding":"","HowToAcknowledge":"","License":"CC0","Name":"Schematic narrative perception and recall (intact)","ReferencesAndLinks":[]},"id":20,"long_description":"Subjects were presented with 16 three-minute stories, consisting of four schematic events drawn from two different scripts (eating at a restaurant or going through the airport). Aside from this shared script structure, the stories varied widely in terms of their characters and storylines, and were presented in two highly dissimilar formats (audiovisual clips or spoken narration).","mean_age":23.70967741935484,"mimetypes":["video/mp4","image/png","audio/x-wav","text/plain","text/csv"],"name":"SchematicNarrative","percent_female":0.41935483870967744,"summary":"Movie clips of schematic narratives","tasks":[{"TR":1.5,"avg_run_duration":756,"id":40,"n_runs_subject":4,"n_subjects":31,"name":"perception","summary":"Audio/visual watching"}],"url":"https://openneuro.org/datasets/ds001510"},{"active":true,"description":{"Acknowledgements":"Only open-source software was employed in this study. We thank their respective authors for making it publicly available.","Authors":["Michael Hanke","Falko R. Kaule","Ayan Sengupta","Florian J. Baumgartner","J. Swaroop Guntupalli","Christian H\u00e4usler","Michael Hoffmann","Vittorio Iacovella","Daniel Kottke","J\u00f6rg Stadler"],"BIDSVersion":"1.0.0-rc3","Description":"Extension of the dataset published in Hanke et al. (2014; doi:10.1038/sdata.2014.3) with additional acquisitions for 15 of the original 20 particpants. These additions include: retinotopic mapping, a localizer paradigm for higher visual areas (FFA, EBA, PPA), and another 2h movie recording with 3T full-brain BOLD fMRI with simultaneous 1000 Hz eyetracking.","Funding":"We acknowledge the support of the Combinatorial NeuroImaging Core Facility at the Leibniz Institute for Neurobiology in Magdeburg, and the German federal state of Saxony-Anhalt, Project: Center for Behavioral Brain Sciences. This research was, in part, also supported by the German Federal Ministry of Education and Research (BMBF) as part of a US-German collaboration in computational neuroscience (CRCNS), co-funded by the BMBF and the US National Science Foundation (BMBF 01GQ1112; NSF 1129855). Work on the data-sharing technology employed for this research was supported by US-German CRCNS project, co-funded by the BMBF and the US National Science Foundation (BMBF 01GQ1411; NSF 1429999).","HowToAcknowledge":"Please follow good scientific practice by citing the most appropriate publication(s) describing the aspects of this datasets that were used in a study.","License":"PDDL","Name":"studyforrest_phase2","ReferencesAndLinks":["http://studyforrest.org"]},"id":11,"long_description":"Participants watched the movie 'Forrest Gump' in eight segments. Due to the movie being presented in German, speech related features are not currently available","mean_age":29.03846153846154,"mimetypes":["video/x-matroska","image/png","audio/x-wav"],"name":"studyforrest","percent_female":0.46153846153846156,"summary":"Forrest Gump movie, in German","tasks":[{"TR":2.00000061,"avg_run_duration":899,"id":16,"n_runs_subject":8,"n_subjects":13,"name":"movie","summary":"Audio Visual Presentation (German)"}],"url":"http://studyforrest.org/"},{"active":true,"description":{"Acknowledgements":"We thanks Courtney Rogers and Jason Gors for help with collecting the data, and Steven Spielberg and George Lucas for such a wonderful movie.","Authors":["J. Swaroop Guntupalli","Yaroslav O. Halchenko","James V. Haxby"],"BIDSVersion":"1.0.1","Funding":"Funding was provided by National Institutes of Mental Health grant 5R01MH075706 (Haxby), and by a graduate fellowship from the Neukom Institute for Computational Sciences at Dartmouth (Guntupalli).","HowToAcknowledge":"Please cite Haxby et al.(2011). doi:10.1016/j.neuron.2011.08.026","License":"PDDL","Name":"Dartmouth Raiders Dataset","ReferencesAndLinks":["doi:10.1016/j.neuron.2011.08.026"]},"id":10,"long_description":"The ~2 hour long film (Raiders of the Lost Ark) was presented in eight parts (corresponding to 8 runs) in two sessions with 4 runs in each session. Each movie part was of approximately the same duration (~14.5 min), with about 20 seconds of movie overlap between consecutive parts (For example, last 20 seconds of the movie at the end of the first run were shown at the beginning of the 2nd run).","mean_age":null,"mimetypes":["video/x-m4v","image/png","audio/x-wav","text/plain","text/csv"],"name":"Raiders","percent_female":null,"summary":"Raiders of the Lost Ark movie","tasks":[{"TR":2.5,"avg_run_duration":849,"id":9,"n_runs_subject":8,"n_subjects":11,"name":"raiders","summary":"AV Presentation: Raiders of the Lost Ark"}],"url":"https://github.com/HaxbyLab/raiders_data"},{"active":true,"description":{"Acknowledgments":"We thank Jason Gors, Kelsey G. Wheeler J. Swaroop Guntupalli, Matteo Visconti di Oleggio Castello, M. Ida Gobbini, Terry Sacket, and the rest of the DBIC (Dartmouth Brain Imaging Center) personnel for assistance in data collection/curation.","Authors":["Samuel A. Nastase","Yaroslav O. Halchenko","Andrew C. Connolly","James V. Haxby"],"BIDSVersion":"1.0.1","Funding":["5R01MH075706","F32MH085433-01A1","NSF1129764"],"HowToAcknowledge":"If you find this data set useful, please cite the following paper: Nastase, S. A., Connolly, A. C., Oosterhof, N. N., Halchenko, Y. O., Guntupalli, J. S., di Oleggio Castello, M. V., Gors, J., Gobbini, M. I., & Haxby, J. V. (2017). Attention selectively reshapes the geometry of distributed semantic representation. Cerebral Cortex.","License":"PDDL","Name":"Neural responses to naturalistic clips of animals"},"id":9,"long_description":"Participants watched four segments of the Life nature documentary, narrated by David Attenborough. Due to the nature of the stimulus, no faces were presented to participants.","mean_age":null,"mimetypes":["video/x-matroska","image/png","audio/x-wav","text/plain","text/csv"],"name":"Life","percent_female":null,"summary":"Four segments of the Life nature documentary","tasks":[{"TR":2.5,"avg_run_duration":942,"id":8,"n_runs_subject":4,"n_subjects":19,"name":"life","summary":"AV Presentation"}],"url":"http://datasets.datalad.org/?dir=/labs/haxby/life"},{"active":true,"description":{"Acknowledgements":"","Authors":["E.S. Finn","P.R. Corlett","G. Chen","P.A. Bandettini","R.T. Constable"],"BIDSVersion":"1.0.1","DatasetDOI":"10.18112/openneuro.ds001338.v1.0.0","Funding":"","HowToAcknowledge":"Please cite original paper:\n\nFinn ES, Corlett PR, Chen G, Bandettini PA, Constable RT. (2018) \"Trait paranoia shapes inter-subject synchrony in brain activity during an ambiguous social narrative.\" Nature Communications, 9: 2043. https://doi.org/10.1038/s41467-018-04387-2","License":"Creative Commons Attribution-NonCommercial 4.0 International","Name":"ParanoiaStory","ReferencesAndLinks":[]},"id":18,"long_description":"22 healthy participants listening to an original audio narrative designed to elicit individual variation along an axis of suspicion/paranoia.","mean_age":26.954545454545453,"mimetypes":["audio/x-wav","text/plain","text/csv"],"name":"ParanoiaStory","percent_female":0.5,"summary":"Narrative designed to elicit individual variation in paranoia","tasks":[{"TR":1.0,"avg_run_duration":436,"id":38,"n_runs_subject":3,"n_subjects":22,"name":"story","summary":"Audio narrative"}],"url":"https://openneuro.org/datasets/ds001338"},{"active":true,"description":{"Authors":["Chen, J.","Leong, Y.C.","Honey, C.J.","Yong C.H.","Norman, K.A.","& Hasson, U.."],"BIDSVersion":"1.0.2","Funding":"National Institutes of Health (1R01MH112357-01 and 1R01MH112566-01)","Name":"Sherlock","ReferencesAndLinks":["https://www.nature.com/neuro/journal/v20/n1/full/nn.4450.html"]},"id":21,"long_description":"Sixteen subjects watched the first 50 minutes of Episode 1 of BBC's Sherlock. The movie was split into two parts of approximately equal length. Immediately afterward, subjects described aloud what they recalled from the movie. Note: Due to missing stimuli, only the first run is currently available.","mean_age":null,"mimetypes":["video/x-m4v","image/png","audio/x-wav","text/plain","text/csv"],"name":"Sherlock","percent_female":null,"summary":"BBC's Sherlock episode","tasks":[{"TR":1.5,"avg_run_duration":1419,"id":41,"n_runs_subject":1,"n_subjects":16,"name":"sherlockPart1","summary":"Audio/visual watching"}],"url":"https://openneuro.org/datasets/ds001132/"},{"active":true,"description":{"Authors":["Zadbood, A.","Chen, J.","Leong, Y.C.","Norman, K.A.","Hasson, U."],"BIDSVersion":"1.0.2","Funding":"National Institutes of Health (1R01MH112357-01 and 1R01MH112566-01)","Name":"Sherlock_Merlin","ReferencesAndLinks":["https://academic.oup.com/cercor/article/doi/10.1093/cercor/bhx202/4080827/How-We-Transmit-Memories-to-Other-Brains"]},"id":5,"long_description":"This dataset includes the data of 18 particpants who watched Sherlock movie and data of 18 participants who watched Merlin movie.","mean_age":21.72222222222222,"mimetypes":["video/mp4","image/png","audio/x-wav","text/plain","video/x-m4v","text/csv"],"name":"SherlockMerlin","percent_female":0.6111111111111112,"summary":"Sherlock and Merlin TV episodes","tasks":[{"TR":1.5,"avg_run_duration":1543,"id":4,"n_runs_subject":1,"n_subjects":18,"name":"MerlinMovie","summary":"AV Presentation: Merlin Episode"},{"TR":1.5,"avg_run_duration":1475,"id":45,"n_runs_subject":1,"n_subjects":18,"name":"SherlockMovie","summary":"AV Presentation: Sherlock Episode"}],"url":"https://openneuro.org/datasets/ds001110"},{"active":true,"description":{"Acknowledgements":"","Authors":["Aly, M.","Chen, J.","Turk-Browne, N.B.","Hasson, U."],"BIDSVersion":"1.1.1","DatasetDOI":"10.18112/openneuro.ds001545.v1.1.0","Funding":"National Institutes of Health (R01MH112357-01 and R01-EY021755)","HowToAcknowledge":"Please cite the paper in References And Links. ","License":"","Name":"Learning Naturalistic Temporal Structure in the Posterior Medial Network","ReferencesAndLinks":["https://www.mitpressjournals.org/doi/full/10.1162/jocn_a_01308"]},"id":19,"long_description":"Participants watched three different clips from the movie 'The Grand Budapest Hotel', six times each. One clip was 'intact' (viewed in its original order); one clip was scrambled but viewed in the same scrambled order for all six repetitions ('scrambled-fixed'). The last clip was also scrambled, but viewed in a different scrambled order for each of the six repetitions ('scrambled-random').","mean_age":23.033333333333335,"mimetypes":["video/mp4","image/png","audio/x-wav","text/plain","text/csv"],"name":"LearningTemporalStructure","percent_female":0.6,"summary":"Clips from the movie The Grand Budapest Hotel","tasks":[{"TR":1.5,"avg_run_duration":400,"id":39,"n_runs_subject":3,"n_subjects":30,"name":"movie","summary":"Movie watching, six clips each run"}],"url":"https://openneuro.org/datasets/ds001545"},{"active":false,"description":{"Authors":["Yeshurun, Y., Nguyen, M., & Hasson, U."],"BIDSVersion":"1.0.2","Funding":"National Institutes of Health (1R01MH112357-01 and 1R01MH112566-01)","Name":"Milky-Vodka","ReferencesAndLinks":["http://www.pnas.org/content/114/35/9475.short"]},"id":25,"long_description":"Two distinct narratives were created by changing only a few words in each sentence (e.g., \u201che\u201d to \u201cshe\u201d or \u201csobbing\u201d to \u201claughing\u201d) while preserving the grammatical structure across stories. 18 subjects listened to story 1; 18 subjects listened to story 2, and 18 subjects listened to both synonym and scrambled control conditions.","mean_age":null,"mimetypes":[],"name":"Milky-Vodka","percent_female":null,"summary":"Two audio narratives","tasks":[{"TR":1.5,"avg_run_duration":445,"id":46,"n_runs_subject":1,"n_subjects":1,"name":"milky","summary":"Milky Way story"}],"url":"https://openneuro.org/datasets/ds001131"},{"active":false,"description":{"Authors":["J. Chen ","C. J. Honey ","E. Simony ","M. J. Arcaro  "," K. A. Norman ","U. Hasson "],"BIDSVersion":"1.0.2","Funding":"This work was supported by the National Institutes of Health (R01-MH094480 and 2T32MH065214-11).","Name":"Twilight Zone Movie Watching Dataset","ReferencesAndLinks":["https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhv155#86168991"]},"id":26,"long_description":"24 subjects watched a complete 25-minute black-and-white television episode (the Twilight Zone, https://en.wikipedia.org/wiki/The_Lateness_of_the_Hour). They had no instructions other than to attend to the movie.","mean_age":null,"mimetypes":[],"name":"TwilightZone","percent_female":null,"summary":"Black-and-white Twilight Zone episode","tasks":[{"TR":1.0,"avg_run_duration":null,"id":47,"n_runs_subject":1,"n_subjects":1,"name":"watchmovie","summary":"Audio Visual B/W movie"}],"url":"https://openneuro.org/datasets/ds001145"}]
